{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archiebenn/BIOLM0050_kaggle/blob/master/protein_embedding_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch transformers sentencepiece h5py\n"
      ],
      "metadata": {
        "id": "0VmqxlmL0FjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from transformers import T5EncoderModel, T5Tokenizer"
      ],
      "metadata": {
        "id": "KtAqJvCUBCV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DkpkQEla0ysf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip bbinf-26-subcell.zip"
      ],
      "metadata": {
        "id": "72AUFnTSMlrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store the embeddings in a dictionary\n",
        "\n",
        "def getEmbeddings(filename):\n",
        "\n",
        "  embeddings_dict = {}\n",
        "\n",
        "  with h5py.File(filename, 'r') as f:\n",
        "\n",
        "      # Iterate through all keys (protein accessions) in the HDF5 file\n",
        "      for accession in f.keys():\n",
        "\n",
        "          if accession != 'metadata':\n",
        "\n",
        "              embeddings_dict[accession] = f[accession][:] # Load the embedding for each accession\n",
        "\n",
        "  return embeddings_dict\n",
        "\n",
        "\n",
        "filename=\"for_embed_prot_t5.h5\"\n",
        "embeddings_dict = getEmbeddings(filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "pLkSFEWEWbtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cf04138"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv('train.csv')\n",
        "df_kaggle_test= pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce57728f"
      },
      "source": [
        "target_cols = ['cytoplasm', 'nucleus', 'extracellular', 'cell_surface', 'mitochondrion', 'endom']\n",
        "\n",
        "y = df_train[target_cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if embeddings_dict:\n",
        "    # Get the dimension of the embeddings from the first item\n",
        "    embedding_dim = next(iter(embeddings_dict.values())).shape[0]\n",
        "else:\n",
        "    print(\"embeddings_dict is empty. Please check the loading process.\")\n",
        "    embedding_dim = 0 # Or handle this error appropriately\n",
        "\n",
        "X = np.stack(df_train[\"acc\"].apply(\n",
        "    lambda acc: embeddings_dict.get(acc, np.zeros(embedding_dim)) # Use np.zeros for missing embeddings\n",
        "))\n",
        "\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "Lf1OHA9fXky0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "onTcvQHSBCIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbf97cb4"
      },
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate a LogisticRegression model\n",
        "model = LogisticRegression(random_state=42, solver='liblinear', verbose=0)\n",
        "#model=RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Create a MultiOutputClassifier instance\n",
        "multi_output_model = MultiOutputClassifier(estimator=model)\n",
        "\n",
        "# Train the MultiOutputClassifier model\n",
        "multi_output_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Multi-label classification model trained successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Calculate F1 score\n",
        "y_pred = multi_output_model.predict(X_test)\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "print(f\"F1 Score (macro average): {f1:.4f}\")"
      ],
      "metadata": {
        "id": "06nn05hQCUDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ignore all below"
      ],
      "metadata": {
        "id": "nVqDOE5VaZ0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Train a classifier on embeddings\n",
        "2) Predict localisations for the human proteome\n",
        "3) Identify the subset of cell-surface proteins (these are potential immunotherapy targets)\n",
        "4) Rank the predicted cell surface human proteins by how many cancers they are differentially expressed in.\n",
        "5) Manually check targets to using the human protein atlas targets should be:\n",
        "\n",
        "    i) not expressed in all cells\n",
        "\n",
        "    ii) especially not expressed in T-cells"
      ],
      "metadata": {
        "id": "YiwONp7Rkuvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title download genes upregulated in cancer\n",
        "!gdown 1gJmvIiAqFcXdtBkwgAciPkMIZIKsILxV\n",
        "\n"
      ],
      "metadata": {
        "id": "lG-1zH8LaYfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pan_cancer = pd.read_csv(\"pan_cancer_de.csv\").rename(columns={\"ACC\":\"acc\"})"
      ],
      "metadata": {
        "id": "yrTSxomsfOG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_canc_count = df_pan_cancer[[\"acc\",\"canc_type\"]].groupby(\"acc\")['canc_type'].nunique().reset_index()"
      ],
      "metadata": {
        "id": "b9QDSRXmfW0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title download embeddings for human proteome\n",
        "!gdown 1bgY8QuZx3BdNOiVPzo5kJ1ZqZyjqdkS6"
      ],
      "metadata": {
        "id": "dqnwgyIbcHfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename='UP000005640_9606_prot_t5.h5'\n",
        "embeddings_dict_human = getEmbeddings(filename)"
      ],
      "metadata": {
        "id": "L8qL047cc5f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if embeddings_dict:\n",
        "    # Get the dimension of the embeddings from the first item\n",
        "    embedding_dim = next(iter(embeddings_dict.values())).shape[0]\n",
        "else:\n",
        "    print(\"embeddings_dict is empty. Please check the loading process.\")\n",
        "    embedding_dim = 0 # Or handle this error appropriately\n",
        "\n",
        "X = np.stack(df_canc_count[\"acc\"].apply(\n",
        "    lambda acc: embeddings_dict_human.get(acc, np.zeros(embedding_dim)) # Use np.zeros for missing embeddings\n",
        "))\n",
        "\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "btV1sS05hvYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = multi_output_model.predict(X)"
      ],
      "metadata": {
        "id": "tTzQj5l6jDxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hum_preds = pd.DataFrame(y_pred, columns=target_cols)"
      ],
      "metadata": {
        "id": "YMrnkUVVjGjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hum_preds[\"acc\"] = df_canc_count[\"acc\"]"
      ],
      "metadata": {
        "id": "gZRh26ssjeEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_canc_count.merge(df_hum_preds[df_hum_preds.cell_surface==1],on=\"acc\").sort_values(\"canc_type\",ascending=False)"
      ],
      "metadata": {
        "id": "RySit70Tjxim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict localisations at scale"
      ],
      "metadata": {
        "id": "CNmsGA4JEC2a"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57ac77d2"
      },
      "source": [
        "X_kaggle_test = np.stack(df_kaggle_test[\"acc\"].apply(\n",
        "    lambda acc: embeddings_dict.get(acc, np.zeros(embedding_dim)) # Use np.zeros for missing embeddings\n",
        "))\n",
        "\n",
        "print(X_kaggle_test.shape)\n",
        "\n",
        "y_kaggle_pred = multi_output_model.predict(X_kaggle_test)\n",
        "print(\"Predictions generated with shape:\", y_kaggle_pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_df = pd.concat([df_kaggle_test['Id'], pd.DataFrame(y_kaggle_pred, columns=y_train.columns)], axis=1)"
      ],
      "metadata": {
        "id": "SRllLyU8JvB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_df.to_csv(\"seq_t5embed_log_reg.csv\", index=False)"
      ],
      "metadata": {
        "id": "BV9dDQX6pdRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head seq_ohe_log_reg.csv"
      ],
      "metadata": {
        "id": "2nbyCBpRQ9bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ai-medicine/2026/bioinformatics-modular/project_datasets/protein_embeddings"
      ],
      "metadata": {
        "id": "CTgpog6qESUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename='/content/drive/MyDrive/ai-medicine/2026/bioinformatics-modular/project_datasets/protein_embeddings/protein.sequence.embeddings.v12.0.h5'"
      ],
      "metadata": {
        "id": "mONhN267EXFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://stringdb-downloads.org/download/species.v12.0.txt"
      ],
      "metadata": {
        "id": "I6jbM6WzJo4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_spec= pd.read_csv(\"species.v12.0.txt\", delimiter=\"\\t\")"
      ],
      "metadata": {
        "id": "E-0kdfStJ3Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tids = list(df_spec[df_spec.domain == \"Eukaryotes\"][\"#taxon_id\"])"
      ],
      "metadata": {
        "id": "bDBr6O2rKDoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tids"
      ],
      "metadata": {
        "id": "dFiAkB7yKXdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "with h5py.File(filename, 'r') as f:\n",
        "    meta_keys = f['metadata'].attrs.keys()\n",
        "    for key in meta_keys:\n",
        "        print(key, f['metadata'].attrs[key])\n",
        "\n",
        "    #embedding = f['embeddings'][:]\n",
        "    #proteins = f['proteins'][:]\n",
        "    print(type( f['species']))\n",
        "    counter=0\n",
        "\n",
        "    for species in tids[0:2]:\n",
        "      print(species)\n",
        "      species_str = str(species)\n",
        "      embeddings = f['species'][species_str]['embeddings'][:]\n",
        "      proteins = f['species'][species_str]['proteins'][:]\n",
        "      tax_pred = multi_output_model.predict(embeddings)\n",
        "      # protein names are stored as bytes, convert them to strings\n",
        "      proteins = [p.decode('utf-8') for p in proteins]"
      ],
      "metadata": {
        "id": "75SrziDDEGtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import h5py\n",
        "\n",
        "# Initialize an empty list to store DataFrames for each species\n",
        "all_predictions_dfs = []\n",
        "\n",
        "# Re-open the HDF5 file and iterate through the species\n",
        "with h5py.File(filename, 'r') as f:\n",
        "    print(\"Starting prediction and concatenation for selected eukaryotic species...\")\n",
        "\n",
        "    # Iterate through the first two eukaryotic species (as in previous execution)\n",
        "    counter =0\n",
        "    for species_id in tids:\n",
        "        species_str = str(species_id)\n",
        "        counter +=1\n",
        "        print(\"doing species\", species_str, counter)\n",
        "        # Check if the species_str is a key in f['species']\n",
        "        if species_str in f['species']:\n",
        "            embeddings = f['species'][species_str]['embeddings'][:]\n",
        "            proteins = f['species'][species_str]['proteins'][:]\n",
        "            tax_pred = multi_output_model.predict(embeddings)\n",
        "\n",
        "            # protein names are stored as bytes, convert them to strings\n",
        "            proteins_decoded = [p.decode('utf-8') for p in proteins]\n",
        "\n",
        "            # Create a DataFrame for the current species' predictions\n",
        "            df_current_species = pd.DataFrame(tax_pred, columns=target_cols)\n",
        "            df_current_species.insert(0, 'protein_accession', proteins_decoded)\n",
        "            df_current_species.insert(0, 'taxon_id', species_id) # Add taxon_id as a separate column\n",
        "\n",
        "            all_predictions_dfs.append(df_current_species)\n",
        "            print(f\"  Processed taxon {species_id} with {len(proteins_decoded)} proteins. Added to list.\")\n",
        "        else:\n",
        "            print(f\"  Species ID {species_id} not found in the HDF5 file. Skipping.\")\n",
        "\n",
        "# Concatenate all individual species DataFrames into one large DataFrame\n",
        "if all_predictions_dfs:\n",
        "    combined_predictions_df = pd.concat(all_predictions_dfs, ignore_index=True)\n",
        "    print(\"\\nSuccessfully concatenated predictions for all processed taxa.\")\n",
        "    print(\"Shape of combined_predictions_df:\", combined_predictions_df.shape)\n",
        "    print(\"First 5 rows of combined_predictions_df:\")\n",
        "    print(combined_predictions_df.head())\n",
        "else:\n",
        "    print(\"\\nNo predictions were generated. The 'all_predictions_dfs' list is empty.\")\n",
        "\n",
        "# Note to user: This cell now performs the full iteration and DataFrame creation.\n",
        "# You may want to modify or remove the loop in the previous cell (75SrziDDEGtr)\n",
        "# if you no longer wish for it to be executed separately.\n",
        "combined_predictions_df.to_csv('euk_loc_t5_logreg_preds.csv')"
      ],
      "metadata": {
        "id": "NBW40NtCG5pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l euk_loc_t5_logreg_preds.csv"
      ],
      "metadata": {
        "id": "LwBjl5BvOTir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loc=pd.read_csv(\"euk_loc_t5_logreg_preds.csv\")"
      ],
      "metadata": {
        "id": "S5uI0JKvOFDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loc_mean=df_loc.groupby(\"taxon_id\").sum(numeric_only=True).drop(columns=[\"Unnamed: 0\"])"
      ],
      "metadata": {
        "id": "iCFvjdezOUdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = df_loc_mean.div(df_loc_mean.sum(axis=1), axis=0)"
      ],
      "metadata": {
        "id": "CukG9gfLTlnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=df_loc_mean.copy()"
      ],
      "metadata": {
        "id": "CwwWu1hrYmUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"total\"] = result.select_dtypes(include=\"number\").sum(axis=1)"
      ],
      "metadata": {
        "id": "8ZTMiMcyTtSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spec.rename(columns={\"#taxon_id\":\"taxon_id\"}).merge(result.reset_index(), left_on=\"taxon_id\", right_on=\"taxon_id\")"
      ],
      "metadata": {
        "id": "h8ZQCuLHPACX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}