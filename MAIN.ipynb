{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61bc046d-6d9d-4867-be33-1807ac110855",
   "metadata": {},
   "source": [
    "# Kaggle Challenge - where do proteins localise?  \n",
    "Understanding where proteins localise is essential for uncovering their biological function and role in disease.  \n",
    "\n",
    "### Challenge details and description  \n",
    "This competition (https://www.kaggle.com/competitions/bbinf-26-subcell) challenges participlants to build a machine learning model that predicts the subcellular localisation of metazoan proteins based on their features:\n",
    "\n",
    "- Proteins can be in more than one location (mutlti label type problem)\n",
    "- Some of the proteins are natural, some are natural sequences, and some are engineered proteins\n",
    "- Inbalanced data - some compartments have many examples (like cytoplasm), while others have less (like peroxisome)\n",
    "- Protein localisation depends on many subtle factors: AA sequence motifs, signal peptides, post-translational modifications, and 3D structure. Capturing all from sequence alone is difficult\n",
    "\n",
    "### Dataset Description\n",
    "Data provided in `.csv` format. The following files are provided:  \n",
    "- `train.csv` - training set\n",
    "- `test.csv` - test set  \n",
    "- `sample_submission.csv` - example of a submission in the correct format  \n",
    "- `metaData.csv` - supplementary information about the data  \n",
    "\n",
    "### Submission and Evaluation  \n",
    "For each protein in the test set, a line with the protein ID followed by 1 or 0 depending on if the corresponding localisation is predicted or not. Example submission file:  \n",
    "\n",
    "```\n",
    "Id,cytoplasm,nucleus,extracellular,cell_surface,mitochondrion,endom\n",
    "5,0,0,0,0,0,0\n",
    "9,1,0,0,0,0,0\n",
    "14,0,0,0,0,0,1\n",
    "15,0,0,0,0,0,0\n",
    "17,1,0,0,0,0,0\n",
    "18,1,1,0,0,0,0\n",
    "```\n",
    "\n",
    "The submitted model is evaluated based on an F1-score (macro averaged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6231811-0de1-4d61-8e6f-34b3de66c994",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039084e4-aa33-4528-834e-e4ef08f7faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn  \n",
    "import h5py\n",
    "import os\n",
    "from sklearn import tree  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d6af3-11f4-4b80-ae76-cf63bbcd484c",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4639be-9f00-408a-8999-e565f9ddb1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DF length: 16077\n",
      "Test/validation DF length: 4377\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>acc</th>\n",
       "      <th>partition</th>\n",
       "      <th>cytoplasm</th>\n",
       "      <th>nucleus</th>\n",
       "      <th>extracellular</th>\n",
       "      <th>cell_surface</th>\n",
       "      <th>mitochondrion</th>\n",
       "      <th>endom</th>\n",
       "      <th>sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>aa_frac_M</th>\n",
       "      <th>aa_frac_N</th>\n",
       "      <th>aa_frac_P</th>\n",
       "      <th>aa_frac_Q</th>\n",
       "      <th>aa_frac_R</th>\n",
       "      <th>aa_frac_S</th>\n",
       "      <th>aa_frac_T</th>\n",
       "      <th>aa_frac_V</th>\n",
       "      <th>aa_frac_W</th>\n",
       "      <th>aa_frac_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P61966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MMRFMLLFSRQGKLRLQKWYLATSDKERKKMVRELMQVVLARKPKM...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Q9VTK2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MSATYTNTITQRRKTAKVRQQQQHQWTGSDLSGESNERLHFRSRST...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>O95858</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MPRGDSEQVRYCARFSYLWLKFSLIIYSTVFWLIGALVLSVGIYAE...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Q9WUX5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MGRSLTCPFGISPACGAQASWSIFGVGTAEVPGTHSHSNQAAAMPH...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Q9NQC3-3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MDGQKKNWKDKVVDLLYWRDIKKTGVVFGASLFLLLSLTVFSIVSV...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id       acc  partition  cytoplasm  nucleus  extracellular  cell_surface  \\\n",
       "0   0    P61966          0          0        0              0             0   \n",
       "1   1    Q9VTK2          0          0        0              0             0   \n",
       "2   2    O95858          3          0        0              0             1   \n",
       "3   3    Q9WUX5          0          1        0              0             0   \n",
       "4   4  Q9NQC3-3          1          0        0              0             0   \n",
       "\n",
       "   mitochondrion  endom                                           sequence  \\\n",
       "0              0      1  MMRFMLLFSRQGKLRLQKWYLATSDKERKKMVRELMQVVLARKPKM...   \n",
       "1              0      1  MSATYTNTITQRRKTAKVRQQQQHQWTGSDLSGESNERLHFRSRST...   \n",
       "2              0      1  MPRGDSEQVRYCARFSYLWLKFSLIIYSTVFWLIGALVLSVGIYAE...   \n",
       "3              0      1  MGRSLTCPFGISPACGAQASWSIFGVGTAEVPGTHSHSNQAAAMPH...   \n",
       "4              0      1  MDGQKKNWKDKVVDLLYWRDIKKTGVVFGASLFLLLSLTVFSIVSV...   \n",
       "\n",
       "   ...  aa_frac_M  aa_frac_N  aa_frac_P  aa_frac_Q  aa_frac_R  aa_frac_S  \\\n",
       "0  ...      0.051      0.013      0.013      0.044      0.063      0.057   \n",
       "1  ...      0.028      0.032      0.044      0.043      0.068      0.080   \n",
       "2  ...      0.034      0.041      0.031      0.027      0.044      0.044   \n",
       "3  ...      0.023      0.036      0.089      0.051      0.050      0.117   \n",
       "4  ...      0.015      0.030      0.015      0.035      0.035      0.070   \n",
       "\n",
       "   aa_frac_T  aa_frac_V  aa_frac_W  aa_frac_Y  \n",
       "0      0.019      0.063      0.013      0.044  \n",
       "1      0.063      0.059      0.025      0.038  \n",
       "2      0.051      0.078      0.014      0.058  \n",
       "3      0.044      0.058      0.008      0.011  \n",
       "4      0.035      0.101      0.015      0.040  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data setup \n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_kaggle_test= pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f'Train DF length: {len(df_train)}')\n",
    "print(f'Test/validation DF length: {len(df_kaggle_test)}')\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab81419-e541-447a-8658-8231fad863ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 1 2]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "# count the partitions in the training data and test data\n",
    "print(df_train[\"partition\"].unique())\n",
    "print(df_kaggle_test[\"partition\"].unique())\n",
    "\n",
    "# so don't need to worry about partition splitting as no overlap with training and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b5372-2778-49b2-866c-ff43a353e051",
   "metadata": {},
   "source": [
    "## Checking for repeats in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e469b13c-c5b7-4e96-b295-a58a3670f8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated IDs: 2425\n",
      "IDs with multiple sequences: 0\n"
     ]
    }
   ],
   "source": [
    "# Get the counts of each ID\n",
    "id_counts = df_train[\"Id\"].value_counts()\n",
    "\n",
    "# checking for any duplicate ids:\n",
    "df_train[\"Id\"].value_counts().head(50)\n",
    "\n",
    "# How many IDs are duplicated (appear more than once)\n",
    "num_duplicated_ids = (id_counts > 1).sum()\n",
    "print(\"Number of duplicated IDs:\", num_duplicated_ids)\n",
    "\n",
    "# group by Id and count unique sequences per ID\n",
    "seq_per_id = df_train.groupby(\"Id\")[\"sequence\"].nunique()\n",
    "\n",
    "# how many Ids have >1 unique sequence?\n",
    "num_ids_with_multiple_sequences = (seq_per_id > 1).sum()\n",
    "print(\"IDs with multiple sequences:\", num_ids_with_multiple_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bd3de3-1e59-4e6c-87a7-900836ec2880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any occurance of same Id after first\n",
    "df_train = df_train.drop_duplicates(subset=\"Id\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b27fdd-0878-484b-b747-e9522a2bf9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write this out to a new .csv for embedding using GPU on google collab\n",
    "df_train.to_csv('train_trimmed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51835ac-d4c8-44b9-9d44-7cea4cbd811c",
   "metadata": {},
   "source": [
    "## Protein embedding\n",
    "At this point I made an embedded h5 file from the protein sequences in `train_trimmed.csv` (see collab notebook).   \n",
    "\n",
    "This was carried out using T4 GPU to create a .h5 embedded protein file for all sequences into fixed length vectors.\n",
    "\n",
    "### TRAIN .h5 embedded file\n",
    "Importing the embedded .h5 protein train file and linking to `df_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42935b4e-e1fb-43c8-8931-bf1bc3daf116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13398"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the embeddings in a dictionary\n",
    "def getEmbeddings(filename):\n",
    "\n",
    "  embeddings_dict = {}\n",
    "\n",
    "  with h5py.File(filename, 'r') as f:\n",
    "\n",
    "      # Iterate through all keys (protein accessions) in the HDF5 file\n",
    "      for accession in f.keys():\n",
    "\n",
    "          if accession != 'metadata':\n",
    "\n",
    "              embeddings_dict[accession] = f[accession][:] # Load the embedding for each accession\n",
    "\n",
    "  return embeddings_dict\n",
    "\n",
    "\n",
    "filename=\"train_protT5_half_2048aa.h5\"\n",
    "embeddings_dict = getEmbeddings(filename)\n",
    "\n",
    "len(embeddings_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b73a8d1-f413-481e-9986-f724bf9907fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double checking to make sure embedding h5 file length = full df length\n",
    "len(embeddings_dict) == len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7b7341-7b93-4fe6-8451-f05654c22c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13398, 1024)\n"
     ]
    }
   ],
   "source": [
    "if embeddings_dict:\n",
    "    # get the dimension of the embeddings from the first item\n",
    "    embedding_dim = next(iter(embeddings_dict.values())).shape[0]\n",
    "else:\n",
    "    print(\"embeddings_dict is empty. Please check the loading process.\")\n",
    "    embedding_dim = 0\n",
    "\n",
    "X = np.stack(df_train[\"Id\"].astype(str).apply(\n",
    "        lambda idx: embeddings_dict[idx]  \n",
    "    )\n",
    ")\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa976c9f-0daa-4b2c-a24d-16b75d61e95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (13398, 1024)\n",
      "Any non-zero values? True\n",
      "Zero rows: 0\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Any non-zero values?\", np.any(X != 0))\n",
    "print(\"Zero rows:\", np.all(X == 0, axis=1).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60d716-0dc8-48a8-91e0-19ad979f099e",
   "metadata": {},
   "source": [
    "## Split the features and targets\n",
    "Need different partitions for training and test sets, as well as target and features columns.  \n",
    "\n",
    "Will start with target as the cytoplasm, nucelus, extracellular, cell~_surface, mitochondria, and endom. \n",
    "\n",
    "And the features are `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6081f1c-6621-4a14-8bb1-8653c44b32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target y\n",
    "target_cols = ['cytoplasm', 'nucleus', 'extracellular', 'cell_surface', 'mitochondrion', 'endom']\n",
    "y = df_train[target_cols]\n",
    "\n",
    "# and do a train-test split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16af620-0a8a-46e5-b2c3-dbbaea1c24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a LogisticRegression model\n",
    "#model = LogisticRegression(random_state=42, solver='liblinear', verbose=0)\n",
    "model=RandomForestClassifier(n_estimators=500, max_depth=None, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Create a MultiOutputClassifier instance\n",
    "multi_output_model = MultiOutputClassifier(estimator=model)\n",
    "\n",
    "# Train the MultiOutputClassifier model\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Multi-label classification model trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083219f5-d8cb-4bb0-acc5-1d42548ef858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculate F1 score\n",
    "y_pred = multi_output_model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"F1 Score (macro average): {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
